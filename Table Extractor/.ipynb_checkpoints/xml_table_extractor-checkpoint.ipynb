{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table Extractor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "import copy\n",
    "import os\n",
    "\n",
    "def clean_excess_space(string_list):\n",
    "    new_list = []\n",
    "    for entry in string_list:\n",
    "        if entry:\n",
    "            new_list.append(re.sub(r\"\"\"\\n\\s{1,}\"\"\", \" \", entry))\n",
    "        else: \n",
    "            new_list.append(entry)\n",
    "    \n",
    "    return new_list\n",
    "\n",
    "def get_all_xmlfiles(path):\n",
    "    files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "    xml_files = list(filter(lambda f: f.endswith('.xml'), files))\n",
    "    return [os.path.join(path, f) for f in xml_files]\n",
    "\n",
    "def get_tables_from_xml_file(filepath):\n",
    "    tree = ET.parse(filepath)\n",
    "    root = ET.tostring(tree.getroot())\n",
    "    content_list = []\n",
    "    total_list = []\n",
    "    sub_header = []\n",
    "    all_tables = []\n",
    "    all_headers = []\n",
    "    counter = 0\n",
    "    table_lists = tree.iter('{http://www.elsevier.com/xml/common/dtd}table')\n",
    "    for table in table_lists:\n",
    "        # get the head column\n",
    "        header = []\n",
    "        lst = table.iter('{http://www.elsevier.com/xml/common/cals/dtd}thead')\n",
    "        for tags in lst:\n",
    "            rows = tags.findall('{http://www.elsevier.com/xml/common/cals/dtd}row')\n",
    "            entry_list = rows[0].findall('{http://www.elsevier.com/xml/common/dtd}entry')\n",
    "            for every_entry in entry_list:\n",
    "                total = ''\n",
    "                for x in every_entry.itertext():\n",
    "                    total = total + x\n",
    "                total_list.append(total)\n",
    "                if 'nameend' in every_entry.attrib.keys():\n",
    "                    if every_entry.attrib['nameend'][:3] == 'col':\n",
    "                        namest = int(every_entry.attrib['namest'][3:])\n",
    "                        nameend = int(every_entry.attrib['nameend'][3:])\n",
    "                        total_list = total_list + ['']*(nameend - namest)\n",
    "            \n",
    "            total_list = clean_excess_space(total_list)\n",
    "            header.append(total_list)\n",
    "            \n",
    "            if len(rows) == 2:\n",
    "                entry_list = rows[1].findall('{http://www.elsevier.com/xml/common/dtd}entry')\n",
    "                for more_entry in entry_list: \n",
    "                    total2 = ''\n",
    "                    for y in more_entry.itertext():\n",
    "                        total2 =  total2 + y \n",
    "                    sub_header.append(total2)\n",
    "                sub_header = clean_excess_space(sub_header)\n",
    "                content_list.append(sub_header)\n",
    "                header.append(sub_header)\n",
    "            \n",
    "        lst2 = table.iter('{http://www.elsevier.com/xml/common/cals/dtd}tbody')\n",
    "        for data in lst2:\n",
    "            rows = data.findall('{http://www.elsevier.com/xml/common/cals/dtd}row')\n",
    "            for row in rows: \n",
    "                entry_list = row.findall('{http://www.elsevier.com/xml/common/dtd}entry')\n",
    "                row_data = []\n",
    "                for additional_entry in entry_list:\n",
    "                    row_data_2 = ''\n",
    "                    for t in additional_entry.itertext():\n",
    "                        row_data_2 = row_data_2 + t\n",
    "                    row_data.append(row_data_2)\n",
    "                content_list.append(clean_excess_space(row_data))\n",
    "        \n",
    "        rows = content_list\n",
    "        df = pd.DataFrame(rows, columns = total_list)\n",
    "        #print(df)\n",
    "        #df.to_csv('Table' + str(counter) + '.csv',encoding='utf-8')\n",
    "        counter = counter + 1\n",
    "        content_list.clear()\n",
    "        all_headers.append(copy.deepcopy(header))\n",
    "        total_list.clear()\n",
    "        sub_header.clear()\n",
    "        all_tables.append(df)\n",
    "    return (all_tables, all_headers)\n",
    "#get_tables_from_xml_file(filepath = 'C:/Users/shulo/OneDrive/Desktop/testing/10.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_properties = pd.DataFrame()\n",
    "paper_index = 1\n",
    "for f in get_all_xmlfiles(path = r'C:/Users/shulo/OneDrive/Desktop/School/Senior Project with Luna/Elsevier_Saeki'):\n",
    "    tables, table_headers = get_tables_from_xml_file(filepath = f)\n",
    "    def reorder_headers(table_headers):\n",
    "        return list(zip(*table_headers))\n",
    "    \n",
    "    def match_string(patterns, strings):\n",
    "        upper_ptns = list(map(str.upper, patterns))\n",
    "        upper_strs = list(map(str.upper, strings))\n",
    "        return any([any([re.search(p, s) for p in upper_ptns]) for s in upper_strs])\n",
    "\n",
    "    for i in range(len(tables)):\n",
    "        table = tables[i]\n",
    "        table_header = table_headers[i]\n",
    "        \n",
    "        matched_table = pd.DataFrame()\n",
    "        r_headers = reorder_headers(table_header)\n",
    "        for all_table_headers in r_headers:\n",
    "            searching_patterns = [['V OC', 'VOC'], ['J SC', 'JSC'], ['FF'], ['PCE']] #Input desired properties \n",
    "            output_headers = ['V OC (V)', 'J SC (mA/cm2)', 'FF (%)', 'PCE (%)'] \n",
    "        for col in range(len(r_headers)):\n",
    "            for p, h in zip(searching_patterns, output_headers):\n",
    "                if match_string(p, r_headers[col]):\n",
    "                    matched_table[0] = table.iloc[:,0]\n",
    "                    matched_table[1] = ''\n",
    "                    matched_table[2] = ''\n",
    "                    if matched_table[0].isnull().values.any(): \n",
    "                        matched_table[1] = table.iloc[:,1]\n",
    "                    if matched_table[1].isnull().values.any(): \n",
    "                        matched_table[2] = table.iloc[:,2]\n",
    "                    matched_table[h] = table.iloc[:, col]\n",
    "        global_idx = []\n",
    "        for row in range(len(matched_table.index)):\n",
    "            to_append = str(paper_index) + '_' + str(i) + '_' + str(row) #Article Index + Table Index + Row Index \n",
    "            global_idx.append(to_append)\n",
    "        matched_table.index = global_idx\n",
    "        all_properties = pd.concat([all_properties, matched_table], sort=False)\n",
    "    paper_index = paper_index + 1 \n",
    "    all_properties.to_csv('Table Extractor Reuslts' + '.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
